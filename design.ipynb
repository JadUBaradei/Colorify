{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:4051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1be44a68200>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import dash_bootstrap_components as dbc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from scipy import ndimage as nd\n",
    "from skimage.segmentation import slic\n",
    "from skimage import img_as_float\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Getting the models\n",
    "# GANS\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "def generator_loss(fake_output , real_y):\n",
    "    real_y = tf.cast( real_y , 'float32' )\n",
    "    return mse( fake_output , real_y )\n",
    "generator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
    "GANS_generator = load_model(r'GANS\\generator.keras', custom_objects={'generator_loss': generator_loss, 'generator_optimizer': generator_optimizer})\n",
    "GANS_discriminator = load_model(r'GANS\\discriminator.keras', custom_objects={'discriminator_loss': discriminator_loss, 'discriminator_optimizer': discriminator_optimizer})\n",
    "\n",
    "# OpenCV\n",
    "openCVModel = load_model(r\"OpenCV\\colorize_opencv.keras\")\n",
    "\n",
    "# OpenCV Improved\n",
    "DIR = \"OpenCV\"\n",
    "PROTOTXT = os.path.join(DIR, r\"model\\colorization_deploy_v2.prototxt\")\n",
    "POINTS = os.path.join(DIR, r\"model\\pts_in_hull.npy\")\n",
    "MODEL = os.path.join(DIR, r\"model\\colorization_release_v2.caffemodel\")\n",
    "net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n",
    "pts = np.load(POINTS)\n",
    "class8 = net.getLayerId(\"class8_ab\")\n",
    "conv8 = net.getLayerId(\"conv8_313_rh\")\n",
    "pts = pts.transpose().reshape(2, 313, 1, 1)\n",
    "net.getLayer(class8).blobs = [pts.astype(\"float32\")]\n",
    "net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]\n",
    "\n",
    "# Autoencoders\n",
    "class ColorAutoEncoder(nn.Module):\n",
    "    def _init_(self):\n",
    "        super()._init_()\n",
    "        self.down1 = nn.Conv2d(1, 64, 3, stride=2, padding=1)\n",
    "        self.down2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
    "        self.down3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\n",
    "        self.down4 = nn.Conv2d(256, 512, 3, stride=2, padding=1)\n",
    "        self.up1 = nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 128, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 64, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 3, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        d1 = self.relu(self.down1(x))\n",
    "        d2 = self.relu(self.down2(d1))\n",
    "        d3 = self.relu(self.down3(d2))\n",
    "        d4 = self.relu(self.down4(d3))\n",
    "        u1 = self.relu(self.up1(d4))\n",
    "        u2 = self.relu(self.up2(torch.cat((u1, d3), dim=1)))\n",
    "        u3 = self.relu(self.up3(torch.cat((u2, d2), dim=1)))\n",
    "        u4 = self.sigmoid(self.up4(torch.cat((u3, d1), dim=1)))\n",
    "        return u4\n",
    "autoEncoderModel = torch.load(r'AutoEncoder\\model.pth')\n",
    "autoEncoderModel.eval()\n",
    "\n",
    "\n",
    "\n",
    "# KNN\n",
    "from joblib import load\n",
    "KNNModel = load(r\"KNN\\knn_model.joblib\")\n",
    "def extract_features(image):\n",
    "    X1 = extract_all(image)\n",
    "    X2 = superpixel(image, False).reshape(-1, 1)\n",
    "    X3 = extract_neighbors_features(image).reshape(-1, 1)\n",
    "    # Print shapes for debugging\n",
    "    print(\"X1 shape:\", X1.shape)\n",
    "    print(\"X2 shape:\", X2.shape)\n",
    "    print(\"X3 shape:\", X3.shape)\n",
    "    X = np.concatenate((X1, X2, X3), axis=1)\n",
    "    return X\n",
    "def superpixel(image, status):    \n",
    "    if status:\n",
    "        segments = slic(img_as_float(image), n_segments=100, sigma=5)\n",
    "    else:\n",
    "        segments = slic(img_as_float(image), n_segments=100, sigma=5, compactness=0.1, channel_axis=None) \n",
    "    return segments\n",
    "def extract_neighbors_features(img, distance=8):\n",
    "    if len(img.shape) > 2:\n",
    "        height, width, _ = img.shape  # For colored images\n",
    "        total_pixels = height * width\n",
    "    else:\n",
    "        height, width = img.shape  # For grayscale images\n",
    "        total_pixels = img.size\n",
    "    X = []\n",
    "    for x in range(height):\n",
    "        for y in range(width):\n",
    "            neighbors = []\n",
    "            for k in range(x - distance, x + distance + 1):\n",
    "                for p in range(y - distance, y + distance + 1):\n",
    "                    if x == k and p == y:\n",
    "                        continue\n",
    "                    elif 0 <= k < height and 0 <= p < width:\n",
    "                        if len(img.shape) > 2:\n",
    "                            neighbors.append(img[k, p])  # For colored images\n",
    "                        else:\n",
    "                            neighbors.append(img[k, p])  # For grayscale images\n",
    "                    else:\n",
    "                        neighbors.append(0)\n",
    "            X.append(sum(neighbors) / len(neighbors))\n",
    "    return np.array(X).reshape(total_pixels, -1)\n",
    "def extract_all(img):\n",
    "    if len(img.shape) > 2:\n",
    "        # For colored images\n",
    "        img2 = img.reshape(-1, img.shape[-1])  # Reshape to 2D array\n",
    "    else:\n",
    "        # For grayscale images\n",
    "        img2 = img.reshape(-1, 1)  # Reshape to 2D array\n",
    "    # First feature is gray value of each pixel\n",
    "    df = pd.DataFrame()\n",
    "    df['GrayValue(I)'] = img2.flatten()\n",
    "    # Second feature is GAUSSIAN filter with sigma=3\n",
    "    gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "    gaussian_img1 = gaussian_img.reshape(-1)\n",
    "    df['Gaussian s3'] = gaussian_img1\n",
    "    # Third feature is GAUSSIAN filter with sigma=7\n",
    "    gaussian_img = nd.gaussian_filter(img, sigma=7)\n",
    "    gaussian_img2 = gaussian_img.reshape(-1)\n",
    "    df['Gaussian s7'] = gaussian_img2\n",
    "    # Fourth feature is generic filter for variance of each pixel with size=3\n",
    "    variance_img = nd.generic_filter(img, np.var, size=3)\n",
    "    variance_img1 = variance_img.reshape(-1)\n",
    "    df['Variance s3'] = variance_img1\n",
    "    return df\n",
    "def colorize_image(grayscale_image, knn_model):\n",
    "    # Extract features from grayscale image\n",
    "    grayscale_features = extract_features(grayscale_image)\n",
    "    # Predict color values using the trained model\n",
    "    predicted_colors = knn_model.predict(grayscale_features)\n",
    "    # Reshape predicted colors to match the size of the grayscale image\n",
    "    predicted_colors_reshaped = predicted_colors.reshape(grayscale_image.shape[0], grayscale_image.shape[1], -1)   \n",
    "    # Check the number of channels in the predicted colors\n",
    "    if predicted_colors_reshaped.shape[-1] == 1:\n",
    "        # If the predicted colors have only one channel, convert to BGR\n",
    "        colorized_image = cv2.cvtColor(predicted_colors_reshaped, cv2.COLOR_GRAY2BGR)\n",
    "    elif predicted_colors_reshaped.shape[-1] == 3:\n",
    "        # If the predicted colors have three channels, no need to convert\n",
    "        colorized_image = predicted_colors_reshaped\n",
    "    else:\n",
    "        raise ValueError(\"Invalid number of channels in predicted colors\")\n",
    "    return colorized_image\n",
    "\n",
    "\n",
    "# Define the Dash app\n",
    "app = dash.Dash(external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Define the layout of the web page\n",
    "app.layout = dbc.Container(\n",
    "    fluid=True,\n",
    "    style={\n",
    "        'backgroundImage': 'url(\"/assets/splash.jpg\")',\n",
    "        'backgroundRepeat': 'no-repeat',\n",
    "        'backgroundPosition': 'center',\n",
    "        'backgroundSize': 'cover',\n",
    "        'position': 'relative', \n",
    "        'minHeight': '100vh',\n",
    "    },\n",
    "    children=[\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                    dbc.Card(\n",
    "                        dbc.CardBody(\n",
    "                            [\n",
    "                                html.H1('Revive your pictures with a splash of colors!', className=\"display-3\"),\n",
    "                                html.P(\"Welcome to Colorify, where black and white memories find their vibrant voice! Reveal the hidden beauty of the past with our innovative models!\",\n",
    "                                       className=\"lead\"),\n",
    "                                html.Hr(className=\"my-2\"),\n",
    "                                html.P(\"Select a model:\"),\n",
    "                                dbc.ButtonGroup(\n",
    "                                    [dbc.Button('Using GANs', id='gans', color=\"primary\", className=\"mr-1\"),\n",
    "                                    #  dbc.Button('Using Autoencoders', id='autoencoders', color=\"primary\", className=\"mr-1\"),\n",
    "                                     dbc.Button('Using OpenCV', id='opencv', color=\"primary\", className=\"mr-1\"),\n",
    "                                     dbc.Button('Using KNN', id='knn', color=\"primary\", className=\"mr-1\"),\n",
    "                                     dbc.Button('Using OpenCV_Improved', id='opencvimproved', color=\"primary\", className=\"mr-1\")\n",
    "                                     ],\n",
    "                                    size=\"lg\"\n",
    "                                ),\n",
    "                            ]\n",
    "                        ),\n",
    "                        className=\"mb-3\",\n",
    "                    ),\n",
    "                    width=12,\n",
    "                    className=\"text-center\",\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        dbc.Row(\n",
    "    [\n",
    "        dbc.Col(\n",
    "            [\n",
    "                html.H2('Original Image:', className=\"mb-2 mt-2\"),\n",
    "\n",
    "                dcc.Upload(\n",
    "                    id='upload-image',\n",
    "                    children=html.Div(['Drag and Drop or ', html.A('Select an Image')]),\n",
    "                    style={\n",
    "                        'width': '450px',  \n",
    "                        'height': '500px',  \n",
    "                        'lineHeight': '300px',  \n",
    "                        'borderWidth': '2px',\n",
    "                        'borderStyle': 'dashed',\n",
    "                        'borderRadius': '5px',\n",
    "                        'textAlign': 'center',\n",
    "                        'margin': '10px',\n",
    "                        'padding': '20px',\n",
    "                    },\n",
    "                    accept='image/*'\n",
    "                ),\n",
    "            ],\n",
    "            width=6,\n",
    "            className=\"text-left\",\n",
    "        ),\n",
    "        dbc.Col(width=3), \n",
    "        dbc.Col(\n",
    "            [\n",
    "                html.H2('Output Image:', className=\"mb-2 mt-2\"),\n",
    "                html.Div(id='output-image-upload', style={\n",
    "                        'width': '450px',  \n",
    "                        'height': '500px',  \n",
    "                        'lineHeight': '300px',  \n",
    "                        'borderWidth': '2px',\n",
    "                        'borderStyle': 'dashed',\n",
    "                        'borderRadius': '5px',\n",
    "                        'textAlign': 'center',\n",
    "                        'margin': '10px',\n",
    "                        'padding': '20px',}),\n",
    "            ],\n",
    "            width=3, \n",
    "            className=\"text-left\",\n",
    "        ),\n",
    "    ],\n",
    "    justify=\"between\", \n",
    "),\n",
    "    ],\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    Output('upload-image', 'children'),\n",
    "    [Input('upload-image', 'contents')],\n",
    "    [State('upload-image', 'filename')]\n",
    ")\n",
    "def update_output(contents, filename):\n",
    "    if contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        try:\n",
    "            if 'jpg' in filename:\n",
    "                data = Image.open(io.BytesIO(decoded))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return html.Div([\n",
    "                'There was an error processing this file.'\n",
    "            ])\n",
    "\n",
    "        return html.Div([\n",
    "            html.Img(src=contents, style={'height':'100%', 'width':'100%'}),\n",
    "            html.Hr(),\n",
    "            html.H5(filename)\n",
    "        ])\n",
    "\n",
    "    return html.Div(['Drag and Drop or ', html.A('Select an Image')])\n",
    "\n",
    "# Callback to display the uploaded image for GANS\n",
    "@app.callback(\n",
    "    Output('output-image-upload', 'children'),\n",
    "    [Input('autoencoders', 'n_clicks'), Input('gans', 'n_clicks'), Input('opencv', 'n_clicks'), Input('knn', 'n_clicks'), Input('opencvimproved', 'n_clicks')],\n",
    "    [State('upload-image', 'contents')]\n",
    ")\n",
    "def GANS_output(gans_n_clicks, autoencoders_n_clicks, opencv_n_clicks, knn_n_clicks,opencvimproved_n_clicks, contents):\n",
    "\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        return None\n",
    "    else:\n",
    "        button_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    \n",
    "    if button_id == 'gans' and autoencoders_n_clicks is not None and contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        image = Image.open(io.BytesIO(decoded)).resize((120, 120))\n",
    "        gray_img_array = (np.asarray(image).reshape((1, 120, 120, 1))) / 255  # Add an extra dimension\n",
    "        y = GANS_generator(gray_img_array).numpy()\n",
    "        output = Image.fromarray(( y[0] * 255 ).astype( 'uint8' )).resize( ( 400 , 400 ) ) \n",
    "        output = np.asarray( output )\n",
    "        # Convert the colorized image to a base64 string\n",
    "        buffered = io.BytesIO()\n",
    "        Image.fromarray(output).save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "        return html.Img(src='data:image/jpeg;base64,'+img_str)\n",
    "    \n",
    "    elif button_id == 'opencv' and opencv_n_clicks is not None and contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        image = Image.open(io.BytesIO(decoded)).resize((120, 120))\n",
    "        image.save(\"temp.png\")\n",
    "        # Use your trained model to colorize images\n",
    "        color_image = cv2.imread(\"temp.png\")\n",
    "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2Lab)\n",
    "        color_image = cv2.resize(color_image, (256, 256))\n",
    "        l_channel = color_image[:,:,0]\n",
    "        l_channel = l_channel.astype('float32') / 255.0\n",
    "        l_channel = np.expand_dims(l_channel, axis=-1)\n",
    "        l_channel = np.expand_dims(l_channel, axis=0)  # add an extra dimension for the batch size\n",
    "        ab_channels = openCVModel.predict(l_channel)\n",
    "        # Ensure that l_channel and ab_channels both have 3 dimensions\n",
    "        l_channel = np.squeeze(l_channel, axis=0)\n",
    "        ab_channels = np.squeeze(ab_channels, axis=0)\n",
    "        colorized_image = np.concatenate((l_channel, ab_channels), axis=-1)\n",
    "        colorized_image = colorized_image * 255.0  # denormalize the pixel values\n",
    "        colorized_image = colorized_image.astype('uint8')  # convert to integer pixel values\n",
    "        # Ensure that colorized_image has 3 channels before converting color spaces\n",
    "        if colorized_image.shape[-1] == 2:\n",
    "            colorized_image = np.concatenate((colorized_image, np.zeros((colorized_image.shape[0], colorized_image.shape[1], 1))), axis=-1)\n",
    "        colorized_image = cv2.cvtColor(colorized_image, cv2.COLOR_Lab2BGR)\n",
    "        colorized_image = cv2.resize(colorized_image, (400, 400))\n",
    "        colorized_image_pil = Image.fromarray(colorized_image)\n",
    "        buffer = io.BytesIO()\n",
    "        colorized_image_pil.save(buffer, format='PNG')\n",
    "        image_base64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "        image_data_url = f'data:image/png;base64,{image_base64}'\n",
    "        os.remove(\"temp.png\")\n",
    "        return html.Img(src=image_data_url)\n",
    "    \n",
    "    elif button_id == 'knn' and knn_n_clicks is not None and contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        image = Image.open(io.BytesIO(decoded)).resize((120, 120))\n",
    "        image.save(\"temp.png\")\n",
    "        input_image = cv2.imread(\"temp.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        colorized_image = colorize_image(input_image, KNNModel)\n",
    "        colorized_image = colorized_image.astype(np.uint8)\n",
    "        colorized_image_pil = Image.fromarray(colorized_image).resize((400, 400))\n",
    "        buffer = io.BytesIO()\n",
    "        colorized_image_pil.save(buffer, format='PNG')\n",
    "        image_base64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "        image_data_url = f'data:image/png;base64,{image_base64}'\n",
    "        return html.Img(src=image_data_url)\n",
    "    \n",
    "    elif button_id == 'opencvimproved' and opencvimproved_n_clicks is not None and contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        image = Image.open(io.BytesIO(decoded)).resize((120, 120))\n",
    "        image.save(\"temp.png\")\n",
    "        image = cv2.imread(\"temp.png\")\n",
    "        scaled = image.astype(\"float32\") / 255.0\n",
    "        lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n",
    "        resized = cv2.resize(lab, (224, 224))\n",
    "        L = cv2.split(resized)[0]\n",
    "        L -= 50\n",
    "        net.setInput(cv2.dnn.blobFromImage(L))\n",
    "        ab = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
    "        ab = cv2.resize(ab, (image.shape[1], image.shape[0]))\n",
    "        L = cv2.split(lab)[0]\n",
    "        colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n",
    "        colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
    "        colorized = np.clip(colorized, 0, 1)\n",
    "        colorized = (255 * colorized).astype(\"uint8\")\n",
    "        colorized = cv2.resize(colorized, (400, 400))\n",
    "        colorized_pil = Image.fromarray(colorized)\n",
    "        buffer = io.BytesIO()\n",
    "        colorized_pil.save(buffer, format='PNG')\n",
    "        image_base64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "        image_data_url = f'data:image/png;base64,{image_base64}'\n",
    "        os.remove(\"temp.png\")\n",
    "        return html.Img(src=image_data_url)\n",
    "    \n",
    "    # elif button_id == 'autoencoders' and autoencoders_n_clicks is not None and contents is not None:\n",
    "    #     content_type, content_string = contents.split(',')\n",
    "    #     decoded = base64.b64decode(content_string)\n",
    "    #     image = Image.open(io.BytesIO(decoded)).resize((120, 120))\n",
    "    #     image.save(\"temp.png\")\n",
    "    #     new_gray_img = Image.open('temp.png')\n",
    "    #     new_gray_img = new_gray_img.convert('L')\n",
    "    #     transform = transforms.Compose([\n",
    "    #         transforms.Resize((256, 256)), \n",
    "    #         transforms.ToTensor(),\n",
    "    #     ])\n",
    "    #     new_gray_img = transform(new_gray_img).unsqueeze(0)\n",
    "    #     DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use GPU if available\n",
    "    #     new_gray_img = new_gray_img.to(DEVICE)\n",
    "    #     model = autoEncoderModel.to(DEVICE)\n",
    "    #     with torch.no_grad():\n",
    "    #         output = model(new_gray_img)\n",
    "    #         output_image = output.cpu().squeeze().numpy()\n",
    "    #     input_image = new_gray_img.cpu().squeeze().numpy()\n",
    "    #     output_image = np.transpose(output_image, (1, 2, 0))\n",
    "    #     output_image = Image.fromarray((output_image * 255).astype(np.uint8))\n",
    "    #     buffer = io.BytesIO()\n",
    "    #     output_image.save(buffer, format='PNG')\n",
    "    #     image_base64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "    #     image_data_url = f'data:image/png;base64,{image_base64}'\n",
    "    #     os.remove(\"temp.png\")\n",
    "    #     return html.Img(src=image_data_url)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(port=4051)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
